{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 测试\n",
    "使用[MNIST](http://yann.lecun.com/exdb/mnist/)数据集来做测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: (17500, 784)\n",
      "train: (39375, 784)\n",
      "validation: (13125, 784)\n",
      "label shape (13125,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:169: RuntimeWarning: overflow encountered in exp\n",
      "  data = np.exp(data)\n",
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:171: RuntimeWarning: invalid value encountered in true_divide\n",
      "  p = data / s\n",
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:173: RuntimeWarning: divide by zero encountered in log\n",
      "  logp = np.log(p)\n",
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:174: RuntimeWarning: invalid value encountered in multiply\n",
      "  return -np.sum(np.multiply(self.truth, logp), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均loss:nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:38: RuntimeWarning: invalid value encountered in less\n",
      "  cp[cp < 0] = 0\n",
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:45: RuntimeWarning: invalid value encountered in less\n",
      "  cp[cp < 0] = 0\n",
      "D:\\Code\\myworks\\机器学习算法实现\\neural_network\\neural_network.py:46: RuntimeWarning: invalid value encountered in greater\n",
      "  cp[cp > 0] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n",
      "validation accuracy:  0.0976761904762\n",
      "平均loss:nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from neural_network import Network\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([k for k in range(10)])\n",
    "\n",
    "mnist = fetch_mldata('MNIST original', data_home='../datasets/MNIST')\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data = min_max_scaler.fit_transform(mnist.data.astype('float64'))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, mnist.target)\n",
    "print('test:', X_test.shape)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train)\n",
    "print('train:', X_train.shape)\n",
    "print('validation:', X_val.shape)\n",
    "print('label shape', y_val.shape)\n",
    "img = np.random.choice(range(X_train.shape[0]))\n",
    "img = X_train[img].reshape((28, 28))\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "y_train = lb.transform(y_train)\n",
    "net = Network([784, 300, 10])\n",
    "batch_size = 2000\n",
    "for epoc in range(100):\n",
    "    time_start = datetime.now()\n",
    "    for left in range(0, X_train.shape[0], batch_size):\n",
    "        right = min(left+batch_size, X_train.shape[0])\n",
    "        X = X_train[left:right, :]\n",
    "        y = y_train[left:right, :]\n",
    "        net.fit(X, y)\n",
    "        y_pred = net.predict(X_val)\n",
    "        y_pred = y_pred.argmax(1).reshape((-1,))\n",
    "        eql = y_pred == y_val\n",
    "        print('validation accuracy: ', np.sum(eql)/eql.shape[0])\n",
    "    print('epoc: %d, time: %fs.'%(epoc, (datetime.now()-time_start).seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 存在的问题\n",
    "- 算法的效率并不高，一个epoc大概要16s\n",
    "- 计算softmax时，偶尔会出现溢出的问题\n",
    "- 准确率并不高，最高才59%左右，和mnist官网上给的数据差距很大\n",
    "- batch模式训练时，loss值会来回震荡\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
