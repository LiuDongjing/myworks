{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "08d60024-6a2f-4d93-8d3e-58abc10e9425"
    }
   },
   "source": [
    "###### 反向传播算法推导(三层神经网络为例)\n",
    "## 符号说明\n",
    "- i、j和k分别代表输入层、隐含层和输出层的神经元序号\n",
    "- $net_x$表示神经元x未经过激活函数的输出\n",
    "- $y_x$表示神经元x经过激活函数后的输出\n",
    "- $f(\\cdot)$表示激活函数\n",
    "- $t_k$表示输出层的真实值\n",
    "- 损失函数$L(\\mathcal{W}) = \\frac{1}{2}\\sum_k (y_k - t_k)^2$(加个系数方便后面求导)\n",
    "\n",
    "参考下面这个示意图($net_i$和$y_i$都和输入相等)\n",
    "![](network.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 更新隐含层到输出层的权重\n",
    "针对$W_{j,k}$，计算梯度\n",
    "    $$\n",
    "    \\frac{\\partial{L}}{\\partial{W_{j,k}}}=\\frac{\\partial{L}}{\\partial{net_k}}\\cdot \\frac{\\partial{net_k}}{\\partial{W_{j,k}}}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{L}}{\\partial{net_k}} = \\frac{\\partial{L}}{\\partial{y_k}} \\cdot \\frac{\\partial{y_k}}{\\partial{net_k}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "容易得到$$\\frac{\\partial{L}}{\\partial{y_k}} = y_k - t_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial{L}}{\\partial{net_k}} &=& (y_k - t_k) \\frac{\\partial{y_k}}{\\partial{net_k}}\\\\\n",
    "&=&(y_k - t_k)f^{'}(net_k)\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为有$$net_k = \\sum_x W_{x, k}\\cdot y_x$$\n",
    "所以$$\\frac{\\partial{net_k}}{\\partial{W_{j,k}}} = y_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上可以得到\n",
    "$$\\frac{\\partial{L}}{\\partial{W_{j,k}}} = (y_k - t_k)f^{'}(net_k)y_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么k号输出神经元隐含层到输出层权重参数的梯度为\n",
    "$$\\Delta{W_k} = (y_k - t_k)f^{'}(net_k)Y_{hidden}$$\n",
    "\n",
    "**注意** 这里约定$W_k$和$Y_{hidden}$都是行向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有个问题，如果有多个输出怎么办？每个输出都会更新上一层的权重，难道取平均？不对，每个输出神经元对应的都是自己的权重，更新的也只是自己的。\n",
    "那么隐含层到输出层所有的权重的梯度为(这里没办法编程矩阵运算，先放着吧)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新输入层到隐含层的权重\n",
    "要求的是损失函数相对于i号神经元(输入层)但j号神经元(隐含层)的权重\n",
    "$$\\frac{\\partial{L}}{\\partial{W_{i,j}}}=\\frac{\\partial{L}}{\\partial{net_j}}\\cdot \\frac{\\partial{net_j}}{\\partial{W_{i,j}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同隐含层的关系有\n",
    "$$\\frac{\\partial{net_j}}{\\partial{W_{i,j}}} = y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{L}}{\\partial{net_j}} = \\frac{\\partial{L}}{\\partial{y_j}}\\cdot \\frac{\\partial{y_j}}{\\partial{net_j}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里求导时注意把损失函数展开，因为一个隐含层的神经元对应着多个输出层的神经元。\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial{L}}{\\partial{y_j}} &=& \\frac{\\partial}{\\partial{y_j}}\\left[ \\frac{1}{2}\\sum_k (y_k - t_k)^2\\right]\\\\\n",
    "&=&\\sum_k (y_k - t_k)\\frac{\\partial{y_k}}{\\partial{y_j}}\\\\\n",
    "&=&\\sum_k (y_k - t_k)f^{'}(net_k)W_{j,k}\\\\\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，可以得到$$\\frac{\\partial{L}}{\\partial{W_{i,j}}} = f^{'}(net_j) y_i \\sum_k (y_k - t_k)f^{'}(net_k)W_{j,k}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么j号神经元参数的梯度为$$\\Delta W_j = Y_{input}f^{'}(net_j) \\sum_k (y_k - t_k)f^{'}(net_k)(W_{j,k})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简化计算\n",
    "找出每一层公共计算的部分，尽量使用矩阵操作，以方便实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "针对某个参数$W_{x, y}$，损失函数对它的梯度总是可以写成两部分\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial{L}}{\\partial{W_{x, y}}} &=& \\frac{\\partial{L}}{\\partial{net_y}} \\cdot \\frac{\\partial{net_y}}{\\partial{W_{x,y }}}\\\\\n",
    "&=&\\frac{\\partial{L}}{\\partial{net_y}}y_x\\\\\n",
    "&\\rightarrow& \\delta_y \\cdot y_x\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对$\\delta_y$进一步拆分，z是y的下一层神经元\n",
    "$$\\begin{eqnarray}\n",
    "\\delta_y &=& \\frac{\\partial{L}}{\\partial{net_y}}\\\\\n",
    "&=& \\frac{\\partial{L}}{\\partial{y_y}}\\cdot \\frac{\\partial{y_y}}{\\partial{net_y}}\\\\\n",
    "&=& f^{'}(net_y)\\frac{\\partial{L}}{\\partial{y_y}}\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial{L}}{\\partial{y_y}} &=& \\sum_z \\frac{\\partial{L}}{\\partial{net_z}}\\cdot \\frac{\\partial{net_z}}{\\partial{y_y}}\\\\\n",
    "&=& \\sum_z \\delta_z \\cdot W_{y, z}\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么有\n",
    "$$\\Delta W_{x, y} = \\delta_y \\cdot y_x$$\n",
    "而\n",
    "$$\\delta_y = f^{'}(net_y)\\sum_z \\delta_z\\cdot W_{y, z}$$\n",
    "这就将每层参数的更新形式定下来了，并且相邻层的关系也给出了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一层网络的$\\delta$记为$\\delta_n$\n",
    "$$\\begin{eqnarray}\n",
    "\\delta_n &=& \\frac{\\partial{L}}{\\partial{net_n}}\\\\\n",
    "&=& \\frac{\\partial{L}}{\\partial{y_n}}\\cdot \\frac{\\partial{y_n}}{\\partial{net_n}}\\\\\n",
    "&=& f^{'}(net_n)\\cdot \\frac{\\partial{L}}{\\partial{y_n}}\n",
    "\\end{eqnarray}$$\n",
    "从$\\delta_n$开始可以依次计算其他层的$\\delta$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵化\n",
    "这里的向量指行向量\n",
    "$$\\vec{\\delta}_k = \\vec{\\delta}_{k+1} \\times \\mathcal{W}^T_{k\\rightarrow k+1} \\cdot f^{'}(\\vec{net}_k)$$\n",
    "\n",
    "$\\mathcal{W}^T_{k\\rightarrow k+1}$是第k层到k+1层的weights，行数对应k层神经元的个数，列数对应k+1层神经元的个数。注意这里的“$\\times$“表示矩阵乘法，而“$\\cdot$”计算两个向量对应元素相乘得到的新向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Delta \\mathcal{W}_{k-1 \\rightarrow k} = \\vec{x}_k^T \\times \\vec{\\delta}_k$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
